{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, sys, time, random, math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from typing import Optional, List\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, df, size = 224, center_crop = True):\n",
    "        self.root_dir = root_dir\n",
    "        self.files = df['file_name'].tolist()\n",
    "        self.findings = df['text'].tolist()\n",
    "        # self.tokenizer = tokenizer\n",
    "        self.image_transforms = transforms.ToTensor()\n",
    "        # transforms.Compose(\n",
    "        #     [\n",
    "        #         transforms.Resize(size, interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "        #         transforms.CenterCrop(size) if center_crop else transforms.RandomCrop(size),\n",
    "        #         transforms.ToTensor(),\n",
    "        #         transforms.Normalize([0.5], [0.5]),\n",
    "        #     ]\n",
    "        # )\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = {}\n",
    "        instance_image = Image.open(\n",
    "            os.path.join(self.root_dir, self.files[idx])\n",
    "        ).convert(\"RGB\")\n",
    "\n",
    "        example[\"instance_images\"] = self.image_transforms(instance_image)\n",
    "        example[\"instance_prompt_ids\"] = self.findings[idx]\n",
    "        # self.tokenizer(\n",
    "        #     self.findings[idx],\n",
    "        #     truncation=True,\n",
    "        #     padding=\"max_length\",\n",
    "        #     max_length=self.tokenizer.model_max_length,\n",
    "        #     return_tensors=\"pt\",\n",
    "        # ).input_ids\n",
    "\n",
    "        return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main path\n",
    "Main_Path = '/home/mcrespo/migros_deepL'\n",
    "# The datasets path under the main path\n",
    "Data_storage = Main_Path + '/sample_flair'\n",
    "save_result_path = Main_Path + '/selora_outputs'\n",
    "reports_path = Data_storage + '/metadata.csv'\n",
    "### folder to save the result.\n",
    "folder_name = 'loras'\n",
    "\n",
    "metadata = pd.read_csv(reports_path)\n",
    "train_df, temp_df = train_test_split(metadata, test_size=0.2, random_state=42)\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_ds = ImageDataset(\n",
    "    root_dir=Data_storage,\n",
    "    df=train_df\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers = 0)\n",
    "### batch size determines the number of steps for each epoch, we are doing 100 epochs. So total number of steps is : 100 * train_df//batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import load_file\n",
    "model_unet = '/work/scratch/mcrespo/output/test_12_26_alldataset/12-27_16h45m08s/selora_outputs/loras/trained_model/final_Unet/diffusion_pytorch_model.safetensors'\n",
    "model_text= '/work/scratch/mcrespo/output/test_12_26_alldataset/12-27_16h45m08s/selora_outputs/loras/trained_model/final_Text/model.safetensors'\n",
    "\n",
    "model_text = load_file(model_text)\n",
    "model_unet = load_file(model_unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_model.embeddings.position_embedding.weight\n",
      "text_model.embeddings.token_embedding.weight\n",
      "text_model.encoder.layers.0.layer_norm1.bias\n",
      "text_model.encoder.layers.0.layer_norm1.weight\n",
      "text_model.encoder.layers.0.layer_norm2.bias\n",
      "text_model.encoder.layers.0.layer_norm2.weight\n",
      "text_model.encoder.layers.0.mlp.fc1.bias\n",
      "text_model.encoder.layers.0.mlp.fc1.lora_A\n",
      "text_model.encoder.layers.0.mlp.fc1.lora_A_temp\n",
      "text_model.encoder.layers.0.mlp.fc1.lora_B\n",
      "text_model.encoder.layers.0.mlp.fc1.lora_B_temp\n",
      "text_model.encoder.layers.0.mlp.fc1.weight\n",
      "text_model.encoder.layers.0.mlp.fc2.bias\n",
      "text_model.encoder.layers.0.mlp.fc2.lora_A\n",
      "text_model.encoder.layers.0.mlp.fc2.lora_A_temp\n",
      "text_model.encoder.layers.0.mlp.fc2.lora_B\n",
      "text_model.encoder.layers.0.mlp.fc2.lora_B_temp\n",
      "text_model.encoder.layers.0.mlp.fc2.weight\n",
      "text_model.encoder.layers.0.self_attn.k_proj.bias\n",
      "text_model.encoder.layers.0.self_attn.k_proj.lora_A\n",
      "text_model.encoder.layers.0.self_attn.k_proj.lora_A_temp\n",
      "text_model.encoder.layers.0.self_attn.k_proj.lora_B\n",
      "text_model.encoder.layers.0.self_attn.k_proj.lora_B_temp\n",
      "text_model.encoder.layers.0.self_attn.k_proj.weight\n",
      "text_model.encoder.layers.0.self_attn.out_proj.bias\n",
      "text_model.encoder.layers.0.self_attn.out_proj.lora_A\n",
      "text_model.encoder.layers.0.self_attn.out_proj.lora_A_temp\n",
      "text_model.encoder.layers.0.self_attn.out_proj.lora_B\n",
      "text_model.encoder.layers.0.self_attn.out_proj.lora_B_temp\n",
      "text_model.encoder.layers.0.self_attn.out_proj.weight\n",
      "text_model.encoder.layers.0.self_attn.q_proj.bias\n",
      "text_model.encoder.layers.0.self_attn.q_proj.lora_A\n",
      "text_model.encoder.layers.0.self_attn.q_proj.lora_A_temp\n",
      "text_model.encoder.layers.0.self_attn.q_proj.lora_B\n",
      "text_model.encoder.layers.0.self_attn.q_proj.lora_B_temp\n",
      "text_model.encoder.layers.0.self_attn.q_proj.weight\n",
      "text_model.encoder.layers.0.self_attn.v_proj.bias\n",
      "text_model.encoder.layers.0.self_attn.v_proj.lora_A\n",
      "text_model.encoder.layers.0.self_attn.v_proj.lora_A_temp\n",
      "text_model.encoder.layers.0.self_attn.v_proj.lora_B\n",
      "text_model.encoder.layers.0.self_attn.v_proj.lora_B_temp\n",
      "text_model.encoder.layers.0.self_attn.v_proj.weight\n",
      "text_model.encoder.layers.1.layer_norm1.bias\n",
      "text_model.encoder.layers.1.layer_norm1.weight\n",
      "text_model.encoder.layers.1.layer_norm2.bias\n",
      "text_model.encoder.layers.1.layer_norm2.weight\n",
      "text_model.encoder.layers.1.mlp.fc1.bias\n",
      "text_model.encoder.layers.1.mlp.fc1.lora_A\n",
      "text_model.encoder.layers.1.mlp.fc1.lora_A_temp\n",
      "text_model.encoder.layers.1.mlp.fc1.lora_B\n",
      "text_model.encoder.layers.1.mlp.fc1.lora_B_temp\n",
      "text_model.encoder.layers.1.mlp.fc1.weight\n",
      "text_model.encoder.layers.1.mlp.fc2.bias\n",
      "text_model.encoder.layers.1.mlp.fc2.lora_A\n",
      "text_model.encoder.layers.1.mlp.fc2.lora_A_temp\n",
      "text_model.encoder.layers.1.mlp.fc2.lora_B\n",
      "text_model.encoder.layers.1.mlp.fc2.lora_B_temp\n",
      "text_model.encoder.layers.1.mlp.fc2.weight\n",
      "text_model.encoder.layers.1.self_attn.k_proj.bias\n",
      "text_model.encoder.layers.1.self_attn.k_proj.lora_A\n",
      "text_model.encoder.layers.1.self_attn.k_proj.lora_A_temp\n",
      "text_model.encoder.layers.1.self_attn.k_proj.lora_B\n",
      "text_model.encoder.layers.1.self_attn.k_proj.lora_B_temp\n",
      "text_model.encoder.layers.1.self_attn.k_proj.weight\n",
      "text_model.encoder.layers.1.self_attn.out_proj.bias\n",
      "text_model.encoder.layers.1.self_attn.out_proj.lora_A\n",
      "text_model.encoder.layers.1.self_attn.out_proj.lora_A_temp\n",
      "text_model.encoder.layers.1.self_attn.out_proj.lora_B\n",
      "text_model.encoder.layers.1.self_attn.out_proj.lora_B_temp\n",
      "text_model.encoder.layers.1.self_attn.out_proj.weight\n",
      "text_model.encoder.layers.1.self_attn.q_proj.bias\n",
      "text_model.encoder.layers.1.self_attn.q_proj.lora_A\n",
      "text_model.encoder.layers.1.self_attn.q_proj.lora_A_temp\n",
      "text_model.encoder.layers.1.self_attn.q_proj.lora_B\n",
      "text_model.encoder.layers.1.self_attn.q_proj.lora_B_temp\n",
      "text_model.encoder.layers.1.self_attn.q_proj.weight\n",
      "text_model.encoder.layers.1.self_attn.v_proj.bias\n",
      "text_model.encoder.layers.1.self_attn.v_proj.lora_A\n",
      "text_model.encoder.layers.1.self_attn.v_proj.lora_A_temp\n",
      "text_model.encoder.layers.1.self_attn.v_proj.lora_B\n",
      "text_model.encoder.layers.1.self_attn.v_proj.lora_B_temp\n",
      "text_model.encoder.layers.1.self_attn.v_proj.weight\n",
      "text_model.encoder.layers.10.layer_norm1.bias\n",
      "text_model.encoder.layers.10.layer_norm1.weight\n",
      "text_model.encoder.layers.10.layer_norm2.bias\n",
      "text_model.encoder.layers.10.layer_norm2.weight\n",
      "text_model.encoder.layers.10.mlp.fc1.bias\n",
      "text_model.encoder.layers.10.mlp.fc1.lora_A\n",
      "text_model.encoder.layers.10.mlp.fc1.lora_A_temp\n",
      "text_model.encoder.layers.10.mlp.fc1.lora_B\n",
      "text_model.encoder.layers.10.mlp.fc1.lora_B_temp\n",
      "text_model.encoder.layers.10.mlp.fc1.weight\n",
      "text_model.encoder.layers.10.mlp.fc2.bias\n",
      "text_model.encoder.layers.10.mlp.fc2.lora_A\n",
      "text_model.encoder.layers.10.mlp.fc2.lora_A_temp\n",
      "text_model.encoder.layers.10.mlp.fc2.lora_B\n",
      "text_model.encoder.layers.10.mlp.fc2.lora_B_temp\n",
      "text_model.encoder.layers.10.mlp.fc2.weight\n",
      "text_model.encoder.layers.10.self_attn.k_proj.bias\n",
      "text_model.encoder.layers.10.self_attn.k_proj.lora_A\n",
      "text_model.encoder.layers.10.self_attn.k_proj.lora_A_temp\n",
      "text_model.encoder.layers.10.self_attn.k_proj.lora_B\n",
      "text_model.encoder.layers.10.self_attn.k_proj.lora_B_temp\n",
      "text_model.encoder.layers.10.self_attn.k_proj.weight\n",
      "text_model.encoder.layers.10.self_attn.out_proj.bias\n",
      "text_model.encoder.layers.10.self_attn.out_proj.lora_A\n",
      "text_model.encoder.layers.10.self_attn.out_proj.lora_A_temp\n",
      "text_model.encoder.layers.10.self_attn.out_proj.lora_B\n",
      "text_model.encoder.layers.10.self_attn.out_proj.lora_B_temp\n",
      "text_model.encoder.layers.10.self_attn.out_proj.weight\n",
      "text_model.encoder.layers.10.self_attn.q_proj.bias\n",
      "text_model.encoder.layers.10.self_attn.q_proj.lora_A\n",
      "text_model.encoder.layers.10.self_attn.q_proj.lora_A_temp\n",
      "text_model.encoder.layers.10.self_attn.q_proj.lora_B\n",
      "text_model.encoder.layers.10.self_attn.q_proj.lora_B_temp\n",
      "text_model.encoder.layers.10.self_attn.q_proj.weight\n",
      "text_model.encoder.layers.10.self_attn.v_proj.bias\n",
      "text_model.encoder.layers.10.self_attn.v_proj.lora_A\n",
      "text_model.encoder.layers.10.self_attn.v_proj.lora_A_temp\n",
      "text_model.encoder.layers.10.self_attn.v_proj.lora_B\n",
      "text_model.encoder.layers.10.self_attn.v_proj.lora_B_temp\n",
      "text_model.encoder.layers.10.self_attn.v_proj.weight\n",
      "text_model.encoder.layers.11.layer_norm1.bias\n",
      "text_model.encoder.layers.11.layer_norm1.weight\n",
      "text_model.encoder.layers.11.layer_norm2.bias\n",
      "text_model.encoder.layers.11.layer_norm2.weight\n",
      "text_model.encoder.layers.11.mlp.fc1.bias\n",
      "text_model.encoder.layers.11.mlp.fc1.lora_A\n",
      "text_model.encoder.layers.11.mlp.fc1.lora_A_temp\n",
      "text_model.encoder.layers.11.mlp.fc1.lora_B\n",
      "text_model.encoder.layers.11.mlp.fc1.lora_B_temp\n",
      "text_model.encoder.layers.11.mlp.fc1.weight\n",
      "text_model.encoder.layers.11.mlp.fc2.bias\n",
      "text_model.encoder.layers.11.mlp.fc2.lora_A\n",
      "text_model.encoder.layers.11.mlp.fc2.lora_A_temp\n",
      "text_model.encoder.layers.11.mlp.fc2.lora_B\n",
      "text_model.encoder.layers.11.mlp.fc2.lora_B_temp\n",
      "text_model.encoder.layers.11.mlp.fc2.weight\n",
      "text_model.encoder.layers.11.self_attn.k_proj.bias\n",
      "text_model.encoder.layers.11.self_attn.k_proj.lora_A\n",
      "text_model.encoder.layers.11.self_attn.k_proj.lora_A_temp\n",
      "text_model.encoder.layers.11.self_attn.k_proj.lora_B\n",
      "text_model.encoder.layers.11.self_attn.k_proj.lora_B_temp\n",
      "text_model.encoder.layers.11.self_attn.k_proj.weight\n",
      "text_model.encoder.layers.11.self_attn.out_proj.bias\n",
      "text_model.encoder.layers.11.self_attn.out_proj.lora_A\n",
      "text_model.encoder.layers.11.self_attn.out_proj.lora_A_temp\n",
      "text_model.encoder.layers.11.self_attn.out_proj.lora_B\n",
      "text_model.encoder.layers.11.self_attn.out_proj.lora_B_temp\n",
      "text_model.encoder.layers.11.self_attn.out_proj.weight\n",
      "text_model.encoder.layers.11.self_attn.q_proj.bias\n",
      "text_model.encoder.layers.11.self_attn.q_proj.lora_A\n",
      "text_model.encoder.layers.11.self_attn.q_proj.lora_A_temp\n",
      "text_model.encoder.layers.11.self_attn.q_proj.lora_B\n",
      "text_model.encoder.layers.11.self_attn.q_proj.lora_B_temp\n",
      "text_model.encoder.layers.11.self_attn.q_proj.weight\n",
      "text_model.encoder.layers.11.self_attn.v_proj.bias\n",
      "text_model.encoder.layers.11.self_attn.v_proj.lora_A\n",
      "text_model.encoder.layers.11.self_attn.v_proj.lora_A_temp\n",
      "text_model.encoder.layers.11.self_attn.v_proj.lora_B\n",
      "text_model.encoder.layers.11.self_attn.v_proj.lora_B_temp\n",
      "text_model.encoder.layers.11.self_attn.v_proj.weight\n",
      "text_model.encoder.layers.2.layer_norm1.bias\n",
      "text_model.encoder.layers.2.layer_norm1.weight\n",
      "text_model.encoder.layers.2.layer_norm2.bias\n",
      "text_model.encoder.layers.2.layer_norm2.weight\n",
      "text_model.encoder.layers.2.mlp.fc1.bias\n",
      "text_model.encoder.layers.2.mlp.fc1.lora_A\n",
      "text_model.encoder.layers.2.mlp.fc1.lora_A_temp\n",
      "text_model.encoder.layers.2.mlp.fc1.lora_B\n",
      "text_model.encoder.layers.2.mlp.fc1.lora_B_temp\n",
      "text_model.encoder.layers.2.mlp.fc1.weight\n",
      "text_model.encoder.layers.2.mlp.fc2.bias\n",
      "text_model.encoder.layers.2.mlp.fc2.lora_A\n",
      "text_model.encoder.layers.2.mlp.fc2.lora_A_temp\n",
      "text_model.encoder.layers.2.mlp.fc2.lora_B\n",
      "text_model.encoder.layers.2.mlp.fc2.lora_B_temp\n",
      "text_model.encoder.layers.2.mlp.fc2.weight\n",
      "text_model.encoder.layers.2.self_attn.k_proj.bias\n",
      "text_model.encoder.layers.2.self_attn.k_proj.lora_A\n",
      "text_model.encoder.layers.2.self_attn.k_proj.lora_A_temp\n",
      "text_model.encoder.layers.2.self_attn.k_proj.lora_B\n",
      "text_model.encoder.layers.2.self_attn.k_proj.lora_B_temp\n",
      "text_model.encoder.layers.2.self_attn.k_proj.weight\n",
      "text_model.encoder.layers.2.self_attn.out_proj.bias\n",
      "text_model.encoder.layers.2.self_attn.out_proj.lora_A\n",
      "text_model.encoder.layers.2.self_attn.out_proj.lora_A_temp\n",
      "text_model.encoder.layers.2.self_attn.out_proj.lora_B\n",
      "text_model.encoder.layers.2.self_attn.out_proj.lora_B_temp\n",
      "text_model.encoder.layers.2.self_attn.out_proj.weight\n",
      "text_model.encoder.layers.2.self_attn.q_proj.bias\n",
      "text_model.encoder.layers.2.self_attn.q_proj.lora_A\n",
      "text_model.encoder.layers.2.self_attn.q_proj.lora_A_temp\n",
      "text_model.encoder.layers.2.self_attn.q_proj.lora_B\n",
      "text_model.encoder.layers.2.self_attn.q_proj.lora_B_temp\n",
      "text_model.encoder.layers.2.self_attn.q_proj.weight\n",
      "text_model.encoder.layers.2.self_attn.v_proj.bias\n",
      "text_model.encoder.layers.2.self_attn.v_proj.lora_A\n",
      "text_model.encoder.layers.2.self_attn.v_proj.lora_A_temp\n",
      "text_model.encoder.layers.2.self_attn.v_proj.lora_B\n",
      "text_model.encoder.layers.2.self_attn.v_proj.lora_B_temp\n",
      "text_model.encoder.layers.2.self_attn.v_proj.weight\n",
      "text_model.encoder.layers.3.layer_norm1.bias\n",
      "text_model.encoder.layers.3.layer_norm1.weight\n",
      "text_model.encoder.layers.3.layer_norm2.bias\n",
      "text_model.encoder.layers.3.layer_norm2.weight\n",
      "text_model.encoder.layers.3.mlp.fc1.bias\n",
      "text_model.encoder.layers.3.mlp.fc1.lora_A\n",
      "text_model.encoder.layers.3.mlp.fc1.lora_A_temp\n",
      "text_model.encoder.layers.3.mlp.fc1.lora_B\n",
      "text_model.encoder.layers.3.mlp.fc1.lora_B_temp\n",
      "text_model.encoder.layers.3.mlp.fc1.weight\n",
      "text_model.encoder.layers.3.mlp.fc2.bias\n",
      "text_model.encoder.layers.3.mlp.fc2.lora_A\n",
      "text_model.encoder.layers.3.mlp.fc2.lora_A_temp\n",
      "text_model.encoder.layers.3.mlp.fc2.lora_B\n",
      "text_model.encoder.layers.3.mlp.fc2.lora_B_temp\n",
      "text_model.encoder.layers.3.mlp.fc2.weight\n",
      "text_model.encoder.layers.3.self_attn.k_proj.bias\n",
      "text_model.encoder.layers.3.self_attn.k_proj.lora_A\n",
      "text_model.encoder.layers.3.self_attn.k_proj.lora_A_temp\n",
      "text_model.encoder.layers.3.self_attn.k_proj.lora_B\n",
      "text_model.encoder.layers.3.self_attn.k_proj.lora_B_temp\n",
      "text_model.encoder.layers.3.self_attn.k_proj.weight\n",
      "text_model.encoder.layers.3.self_attn.out_proj.bias\n",
      "text_model.encoder.layers.3.self_attn.out_proj.lora_A\n",
      "text_model.encoder.layers.3.self_attn.out_proj.lora_A_temp\n",
      "text_model.encoder.layers.3.self_attn.out_proj.lora_B\n",
      "text_model.encoder.layers.3.self_attn.out_proj.lora_B_temp\n",
      "text_model.encoder.layers.3.self_attn.out_proj.weight\n",
      "text_model.encoder.layers.3.self_attn.q_proj.bias\n",
      "text_model.encoder.layers.3.self_attn.q_proj.lora_A\n",
      "text_model.encoder.layers.3.self_attn.q_proj.lora_A_temp\n",
      "text_model.encoder.layers.3.self_attn.q_proj.lora_B\n",
      "text_model.encoder.layers.3.self_attn.q_proj.lora_B_temp\n",
      "text_model.encoder.layers.3.self_attn.q_proj.weight\n",
      "text_model.encoder.layers.3.self_attn.v_proj.bias\n",
      "text_model.encoder.layers.3.self_attn.v_proj.lora_A\n",
      "text_model.encoder.layers.3.self_attn.v_proj.lora_A_temp\n",
      "text_model.encoder.layers.3.self_attn.v_proj.lora_B\n",
      "text_model.encoder.layers.3.self_attn.v_proj.lora_B_temp\n",
      "text_model.encoder.layers.3.self_attn.v_proj.weight\n",
      "text_model.encoder.layers.4.layer_norm1.bias\n",
      "text_model.encoder.layers.4.layer_norm1.weight\n",
      "text_model.encoder.layers.4.layer_norm2.bias\n",
      "text_model.encoder.layers.4.layer_norm2.weight\n",
      "text_model.encoder.layers.4.mlp.fc1.bias\n",
      "text_model.encoder.layers.4.mlp.fc1.lora_A\n",
      "text_model.encoder.layers.4.mlp.fc1.lora_A_temp\n",
      "text_model.encoder.layers.4.mlp.fc1.lora_B\n",
      "text_model.encoder.layers.4.mlp.fc1.lora_B_temp\n",
      "text_model.encoder.layers.4.mlp.fc1.weight\n",
      "text_model.encoder.layers.4.mlp.fc2.bias\n",
      "text_model.encoder.layers.4.mlp.fc2.lora_A\n",
      "text_model.encoder.layers.4.mlp.fc2.lora_A_temp\n",
      "text_model.encoder.layers.4.mlp.fc2.lora_B\n",
      "text_model.encoder.layers.4.mlp.fc2.lora_B_temp\n",
      "text_model.encoder.layers.4.mlp.fc2.weight\n",
      "text_model.encoder.layers.4.self_attn.k_proj.bias\n",
      "text_model.encoder.layers.4.self_attn.k_proj.lora_A\n",
      "text_model.encoder.layers.4.self_attn.k_proj.lora_A_temp\n",
      "text_model.encoder.layers.4.self_attn.k_proj.lora_B\n",
      "text_model.encoder.layers.4.self_attn.k_proj.lora_B_temp\n",
      "text_model.encoder.layers.4.self_attn.k_proj.weight\n",
      "text_model.encoder.layers.4.self_attn.out_proj.bias\n",
      "text_model.encoder.layers.4.self_attn.out_proj.lora_A\n",
      "text_model.encoder.layers.4.self_attn.out_proj.lora_A_temp\n",
      "text_model.encoder.layers.4.self_attn.out_proj.lora_B\n",
      "text_model.encoder.layers.4.self_attn.out_proj.lora_B_temp\n",
      "text_model.encoder.layers.4.self_attn.out_proj.weight\n",
      "text_model.encoder.layers.4.self_attn.q_proj.bias\n",
      "text_model.encoder.layers.4.self_attn.q_proj.lora_A\n",
      "text_model.encoder.layers.4.self_attn.q_proj.lora_A_temp\n",
      "text_model.encoder.layers.4.self_attn.q_proj.lora_B\n",
      "text_model.encoder.layers.4.self_attn.q_proj.lora_B_temp\n",
      "text_model.encoder.layers.4.self_attn.q_proj.weight\n",
      "text_model.encoder.layers.4.self_attn.v_proj.bias\n",
      "text_model.encoder.layers.4.self_attn.v_proj.lora_A\n",
      "text_model.encoder.layers.4.self_attn.v_proj.lora_A_temp\n",
      "text_model.encoder.layers.4.self_attn.v_proj.lora_B\n",
      "text_model.encoder.layers.4.self_attn.v_proj.lora_B_temp\n",
      "text_model.encoder.layers.4.self_attn.v_proj.weight\n",
      "text_model.encoder.layers.5.layer_norm1.bias\n",
      "text_model.encoder.layers.5.layer_norm1.weight\n",
      "text_model.encoder.layers.5.layer_norm2.bias\n",
      "text_model.encoder.layers.5.layer_norm2.weight\n",
      "text_model.encoder.layers.5.mlp.fc1.bias\n",
      "text_model.encoder.layers.5.mlp.fc1.lora_A\n",
      "text_model.encoder.layers.5.mlp.fc1.lora_A_temp\n",
      "text_model.encoder.layers.5.mlp.fc1.lora_B\n",
      "text_model.encoder.layers.5.mlp.fc1.lora_B_temp\n",
      "text_model.encoder.layers.5.mlp.fc1.weight\n",
      "text_model.encoder.layers.5.mlp.fc2.bias\n",
      "text_model.encoder.layers.5.mlp.fc2.lora_A\n",
      "text_model.encoder.layers.5.mlp.fc2.lora_A_temp\n",
      "text_model.encoder.layers.5.mlp.fc2.lora_B\n",
      "text_model.encoder.layers.5.mlp.fc2.lora_B_temp\n",
      "text_model.encoder.layers.5.mlp.fc2.weight\n",
      "text_model.encoder.layers.5.self_attn.k_proj.bias\n",
      "text_model.encoder.layers.5.self_attn.k_proj.lora_A\n",
      "text_model.encoder.layers.5.self_attn.k_proj.lora_A_temp\n",
      "text_model.encoder.layers.5.self_attn.k_proj.lora_B\n",
      "text_model.encoder.layers.5.self_attn.k_proj.lora_B_temp\n",
      "text_model.encoder.layers.5.self_attn.k_proj.weight\n",
      "text_model.encoder.layers.5.self_attn.out_proj.bias\n",
      "text_model.encoder.layers.5.self_attn.out_proj.lora_A\n",
      "text_model.encoder.layers.5.self_attn.out_proj.lora_A_temp\n",
      "text_model.encoder.layers.5.self_attn.out_proj.lora_B\n",
      "text_model.encoder.layers.5.self_attn.out_proj.lora_B_temp\n",
      "text_model.encoder.layers.5.self_attn.out_proj.weight\n",
      "text_model.encoder.layers.5.self_attn.q_proj.bias\n",
      "text_model.encoder.layers.5.self_attn.q_proj.lora_A\n",
      "text_model.encoder.layers.5.self_attn.q_proj.lora_A_temp\n",
      "text_model.encoder.layers.5.self_attn.q_proj.lora_B\n",
      "text_model.encoder.layers.5.self_attn.q_proj.lora_B_temp\n",
      "text_model.encoder.layers.5.self_attn.q_proj.weight\n",
      "text_model.encoder.layers.5.self_attn.v_proj.bias\n",
      "text_model.encoder.layers.5.self_attn.v_proj.lora_A\n",
      "text_model.encoder.layers.5.self_attn.v_proj.lora_A_temp\n",
      "text_model.encoder.layers.5.self_attn.v_proj.lora_B\n",
      "text_model.encoder.layers.5.self_attn.v_proj.lora_B_temp\n",
      "text_model.encoder.layers.5.self_attn.v_proj.weight\n",
      "text_model.encoder.layers.6.layer_norm1.bias\n",
      "text_model.encoder.layers.6.layer_norm1.weight\n",
      "text_model.encoder.layers.6.layer_norm2.bias\n",
      "text_model.encoder.layers.6.layer_norm2.weight\n",
      "text_model.encoder.layers.6.mlp.fc1.bias\n",
      "text_model.encoder.layers.6.mlp.fc1.lora_A\n",
      "text_model.encoder.layers.6.mlp.fc1.lora_A_temp\n",
      "text_model.encoder.layers.6.mlp.fc1.lora_B\n",
      "text_model.encoder.layers.6.mlp.fc1.lora_B_temp\n",
      "text_model.encoder.layers.6.mlp.fc1.weight\n",
      "text_model.encoder.layers.6.mlp.fc2.bias\n",
      "text_model.encoder.layers.6.mlp.fc2.lora_A\n",
      "text_model.encoder.layers.6.mlp.fc2.lora_A_temp\n",
      "text_model.encoder.layers.6.mlp.fc2.lora_B\n",
      "text_model.encoder.layers.6.mlp.fc2.lora_B_temp\n",
      "text_model.encoder.layers.6.mlp.fc2.weight\n",
      "text_model.encoder.layers.6.self_attn.k_proj.bias\n",
      "text_model.encoder.layers.6.self_attn.k_proj.lora_A\n",
      "text_model.encoder.layers.6.self_attn.k_proj.lora_A_temp\n",
      "text_model.encoder.layers.6.self_attn.k_proj.lora_B\n",
      "text_model.encoder.layers.6.self_attn.k_proj.lora_B_temp\n",
      "text_model.encoder.layers.6.self_attn.k_proj.weight\n",
      "text_model.encoder.layers.6.self_attn.out_proj.bias\n",
      "text_model.encoder.layers.6.self_attn.out_proj.lora_A\n",
      "text_model.encoder.layers.6.self_attn.out_proj.lora_A_temp\n",
      "text_model.encoder.layers.6.self_attn.out_proj.lora_B\n",
      "text_model.encoder.layers.6.self_attn.out_proj.lora_B_temp\n",
      "text_model.encoder.layers.6.self_attn.out_proj.weight\n",
      "text_model.encoder.layers.6.self_attn.q_proj.bias\n",
      "text_model.encoder.layers.6.self_attn.q_proj.lora_A\n",
      "text_model.encoder.layers.6.self_attn.q_proj.lora_A_temp\n",
      "text_model.encoder.layers.6.self_attn.q_proj.lora_B\n",
      "text_model.encoder.layers.6.self_attn.q_proj.lora_B_temp\n",
      "text_model.encoder.layers.6.self_attn.q_proj.weight\n",
      "text_model.encoder.layers.6.self_attn.v_proj.bias\n",
      "text_model.encoder.layers.6.self_attn.v_proj.lora_A\n",
      "text_model.encoder.layers.6.self_attn.v_proj.lora_A_temp\n",
      "text_model.encoder.layers.6.self_attn.v_proj.lora_B\n",
      "text_model.encoder.layers.6.self_attn.v_proj.lora_B_temp\n",
      "text_model.encoder.layers.6.self_attn.v_proj.weight\n",
      "text_model.encoder.layers.7.layer_norm1.bias\n",
      "text_model.encoder.layers.7.layer_norm1.weight\n",
      "text_model.encoder.layers.7.layer_norm2.bias\n",
      "text_model.encoder.layers.7.layer_norm2.weight\n",
      "text_model.encoder.layers.7.mlp.fc1.bias\n",
      "text_model.encoder.layers.7.mlp.fc1.lora_A\n",
      "text_model.encoder.layers.7.mlp.fc1.lora_A_temp\n",
      "text_model.encoder.layers.7.mlp.fc1.lora_B\n",
      "text_model.encoder.layers.7.mlp.fc1.lora_B_temp\n",
      "text_model.encoder.layers.7.mlp.fc1.weight\n",
      "text_model.encoder.layers.7.mlp.fc2.bias\n",
      "text_model.encoder.layers.7.mlp.fc2.lora_A\n",
      "text_model.encoder.layers.7.mlp.fc2.lora_A_temp\n",
      "text_model.encoder.layers.7.mlp.fc2.lora_B\n",
      "text_model.encoder.layers.7.mlp.fc2.lora_B_temp\n",
      "text_model.encoder.layers.7.mlp.fc2.weight\n",
      "text_model.encoder.layers.7.self_attn.k_proj.bias\n",
      "text_model.encoder.layers.7.self_attn.k_proj.lora_A\n",
      "text_model.encoder.layers.7.self_attn.k_proj.lora_A_temp\n",
      "text_model.encoder.layers.7.self_attn.k_proj.lora_B\n",
      "text_model.encoder.layers.7.self_attn.k_proj.lora_B_temp\n",
      "text_model.encoder.layers.7.self_attn.k_proj.weight\n",
      "text_model.encoder.layers.7.self_attn.out_proj.bias\n",
      "text_model.encoder.layers.7.self_attn.out_proj.lora_A\n",
      "text_model.encoder.layers.7.self_attn.out_proj.lora_A_temp\n",
      "text_model.encoder.layers.7.self_attn.out_proj.lora_B\n",
      "text_model.encoder.layers.7.self_attn.out_proj.lora_B_temp\n",
      "text_model.encoder.layers.7.self_attn.out_proj.weight\n",
      "text_model.encoder.layers.7.self_attn.q_proj.bias\n",
      "text_model.encoder.layers.7.self_attn.q_proj.lora_A\n",
      "text_model.encoder.layers.7.self_attn.q_proj.lora_A_temp\n",
      "text_model.encoder.layers.7.self_attn.q_proj.lora_B\n",
      "text_model.encoder.layers.7.self_attn.q_proj.lora_B_temp\n",
      "text_model.encoder.layers.7.self_attn.q_proj.weight\n",
      "text_model.encoder.layers.7.self_attn.v_proj.bias\n",
      "text_model.encoder.layers.7.self_attn.v_proj.lora_A\n",
      "text_model.encoder.layers.7.self_attn.v_proj.lora_A_temp\n",
      "text_model.encoder.layers.7.self_attn.v_proj.lora_B\n",
      "text_model.encoder.layers.7.self_attn.v_proj.lora_B_temp\n",
      "text_model.encoder.layers.7.self_attn.v_proj.weight\n",
      "text_model.encoder.layers.8.layer_norm1.bias\n",
      "text_model.encoder.layers.8.layer_norm1.weight\n",
      "text_model.encoder.layers.8.layer_norm2.bias\n",
      "text_model.encoder.layers.8.layer_norm2.weight\n",
      "text_model.encoder.layers.8.mlp.fc1.bias\n",
      "text_model.encoder.layers.8.mlp.fc1.lora_A\n",
      "text_model.encoder.layers.8.mlp.fc1.lora_A_temp\n",
      "text_model.encoder.layers.8.mlp.fc1.lora_B\n",
      "text_model.encoder.layers.8.mlp.fc1.lora_B_temp\n",
      "text_model.encoder.layers.8.mlp.fc1.weight\n",
      "text_model.encoder.layers.8.mlp.fc2.bias\n",
      "text_model.encoder.layers.8.mlp.fc2.lora_A\n",
      "text_model.encoder.layers.8.mlp.fc2.lora_A_temp\n",
      "text_model.encoder.layers.8.mlp.fc2.lora_B\n",
      "text_model.encoder.layers.8.mlp.fc2.lora_B_temp\n",
      "text_model.encoder.layers.8.mlp.fc2.weight\n",
      "text_model.encoder.layers.8.self_attn.k_proj.bias\n",
      "text_model.encoder.layers.8.self_attn.k_proj.lora_A\n",
      "text_model.encoder.layers.8.self_attn.k_proj.lora_A_temp\n",
      "text_model.encoder.layers.8.self_attn.k_proj.lora_B\n",
      "text_model.encoder.layers.8.self_attn.k_proj.lora_B_temp\n",
      "text_model.encoder.layers.8.self_attn.k_proj.weight\n",
      "text_model.encoder.layers.8.self_attn.out_proj.bias\n",
      "text_model.encoder.layers.8.self_attn.out_proj.lora_A\n",
      "text_model.encoder.layers.8.self_attn.out_proj.lora_A_temp\n",
      "text_model.encoder.layers.8.self_attn.out_proj.lora_B\n",
      "text_model.encoder.layers.8.self_attn.out_proj.lora_B_temp\n",
      "text_model.encoder.layers.8.self_attn.out_proj.weight\n",
      "text_model.encoder.layers.8.self_attn.q_proj.bias\n",
      "text_model.encoder.layers.8.self_attn.q_proj.lora_A\n",
      "text_model.encoder.layers.8.self_attn.q_proj.lora_A_temp\n",
      "text_model.encoder.layers.8.self_attn.q_proj.lora_B\n",
      "text_model.encoder.layers.8.self_attn.q_proj.lora_B_temp\n",
      "text_model.encoder.layers.8.self_attn.q_proj.weight\n",
      "text_model.encoder.layers.8.self_attn.v_proj.bias\n",
      "text_model.encoder.layers.8.self_attn.v_proj.lora_A\n",
      "text_model.encoder.layers.8.self_attn.v_proj.lora_A_temp\n",
      "text_model.encoder.layers.8.self_attn.v_proj.lora_B\n",
      "text_model.encoder.layers.8.self_attn.v_proj.lora_B_temp\n",
      "text_model.encoder.layers.8.self_attn.v_proj.weight\n",
      "text_model.encoder.layers.9.layer_norm1.bias\n",
      "text_model.encoder.layers.9.layer_norm1.weight\n",
      "text_model.encoder.layers.9.layer_norm2.bias\n",
      "text_model.encoder.layers.9.layer_norm2.weight\n",
      "text_model.encoder.layers.9.mlp.fc1.bias\n",
      "text_model.encoder.layers.9.mlp.fc1.lora_A\n",
      "text_model.encoder.layers.9.mlp.fc1.lora_A_temp\n",
      "text_model.encoder.layers.9.mlp.fc1.lora_B\n",
      "text_model.encoder.layers.9.mlp.fc1.lora_B_temp\n",
      "text_model.encoder.layers.9.mlp.fc1.weight\n",
      "text_model.encoder.layers.9.mlp.fc2.bias\n",
      "text_model.encoder.layers.9.mlp.fc2.lora_A\n",
      "text_model.encoder.layers.9.mlp.fc2.lora_A_temp\n",
      "text_model.encoder.layers.9.mlp.fc2.lora_B\n",
      "text_model.encoder.layers.9.mlp.fc2.lora_B_temp\n",
      "text_model.encoder.layers.9.mlp.fc2.weight\n",
      "text_model.encoder.layers.9.self_attn.k_proj.bias\n",
      "text_model.encoder.layers.9.self_attn.k_proj.lora_A\n",
      "text_model.encoder.layers.9.self_attn.k_proj.lora_A_temp\n",
      "text_model.encoder.layers.9.self_attn.k_proj.lora_B\n",
      "text_model.encoder.layers.9.self_attn.k_proj.lora_B_temp\n",
      "text_model.encoder.layers.9.self_attn.k_proj.weight\n",
      "text_model.encoder.layers.9.self_attn.out_proj.bias\n",
      "text_model.encoder.layers.9.self_attn.out_proj.lora_A\n",
      "text_model.encoder.layers.9.self_attn.out_proj.lora_A_temp\n",
      "text_model.encoder.layers.9.self_attn.out_proj.lora_B\n",
      "text_model.encoder.layers.9.self_attn.out_proj.lora_B_temp\n",
      "text_model.encoder.layers.9.self_attn.out_proj.weight\n",
      "text_model.encoder.layers.9.self_attn.q_proj.bias\n",
      "text_model.encoder.layers.9.self_attn.q_proj.lora_A\n",
      "text_model.encoder.layers.9.self_attn.q_proj.lora_A_temp\n",
      "text_model.encoder.layers.9.self_attn.q_proj.lora_B\n",
      "text_model.encoder.layers.9.self_attn.q_proj.lora_B_temp\n",
      "text_model.encoder.layers.9.self_attn.q_proj.weight\n",
      "text_model.encoder.layers.9.self_attn.v_proj.bias\n",
      "text_model.encoder.layers.9.self_attn.v_proj.lora_A\n",
      "text_model.encoder.layers.9.self_attn.v_proj.lora_A_temp\n",
      "text_model.encoder.layers.9.self_attn.v_proj.lora_B\n",
      "text_model.encoder.layers.9.self_attn.v_proj.lora_B_temp\n",
      "text_model.encoder.layers.9.self_attn.v_proj.weight\n",
      "text_model.final_layer_norm.bias\n",
      "text_model.final_layer_norm.weight\n"
     ]
    }
   ],
   "source": [
    "for tensor_name in model_text.keys():\n",
    "    print(tensor_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'named_modules'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel_text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamed_modules\u001b[49m():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'named_modules'"
     ]
    }
   ],
   "source": [
    "for name, layer in model_text.named_modules():\n",
    "    print(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sel_py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
